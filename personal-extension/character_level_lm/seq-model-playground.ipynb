{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "271e06d6",
   "metadata": {},
   "source": [
    "# Seq LM playground\n",
    "\n",
    "Implement the RNN, LSTM and GRU based character based LM for makemore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8f196c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7dd49aeac730>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.nn.init as init\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "import heapq\n",
    "import random\n",
    "from IPython.display import display, Markdown\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "efb7e5c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "619ddfa4",
   "metadata": {},
   "source": [
    "## Step 1: Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0185d12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['emma', 'olivia', 'ava', 'isabella', 'sophia']\n"
     ]
    }
   ],
   "source": [
    "file_path = \"../names.txt\"\n",
    "\n",
    "names = []\n",
    "\n",
    "with open(file_path, \"r\") as f:\n",
    "    for name in f.readlines():\n",
    "        names.append(name.strip())\n",
    "\n",
    "print(names[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b08c301",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32033"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92307d5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'b',\n",
       " 'c',\n",
       " 'd',\n",
       " 'e',\n",
       " 'f',\n",
       " 'g',\n",
       " 'h',\n",
       " 'i',\n",
       " 'j',\n",
       " 'k',\n",
       " 'l',\n",
       " 'm',\n",
       " 'n',\n",
       " 'o',\n",
       " 'p',\n",
       " 'q',\n",
       " 'r',\n",
       " 's',\n",
       " 't',\n",
       " 'u',\n",
       " 'v',\n",
       " 'w',\n",
       " 'x',\n",
       " 'y',\n",
       " 'z']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = sorted(set([l for name in names for l in name]))\n",
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73ec3381",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'.': 0, 'a': 1, 'b': 2, 'c': 3, 'd': 4, 'e': 5, 'f': 6, 'g': 7, 'h': 8, 'i': 9, 'j': 10, 'k': 11, 'l': 12, 'm': 13, 'n': 14, 'o': 15, 'p': 16, 'q': 17, 'r': 18, 's': 19, 't': 20, 'u': 21, 'v': 22, 'w': 23, 'x': 24, 'y': 25, 'z': 26, '<pad>': 27}\n",
      "{0: '.', 1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z', 27: '<pad>'}\n"
     ]
    }
   ],
   "source": [
    "stoi, itos = {}, {}\n",
    "\n",
    "stoi[\".\"] = 0\n",
    "itos[0] = \".\"\n",
    "\n",
    "for i, l in enumerate(vocab):\n",
    "    stoi[l] = i + 1\n",
    "    itos[i + 1] = l\n",
    "\n",
    "stoi[\"<pad>\"] = len(stoi)\n",
    "itos[len(itos)] = \"<pad>\"\n",
    "\n",
    "print(stoi)\n",
    "print(itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b979af08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 25626, Val: 3203, Test: 3204\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "random.seed(42)\n",
    "names_shuffled = names.copy()\n",
    "random.shuffle(names_shuffled)\n",
    "\n",
    "n = len(names_shuffled)\n",
    "n_train = int(0.8 * n)\n",
    "n_val = int(0.1 * n)\n",
    "\n",
    "train_names = names_shuffled[:n_train]\n",
    "val_names = names_shuffled[n_train:n_train + n_val]\n",
    "test_names = names_shuffled[n_train + n_val:]\n",
    "\n",
    "print(f\"Train: {len(train_names)}, Val: {len(val_names)}, Test: {len(test_names)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data(names, padding=False, max_seq_len=None):\n",
    "    # create dataset like\n",
    "    # for name soham -> make it .soham. -> [.,s,o,h,a,m] ---> [s,o,h,a,m,.]\n",
    "\n",
    "    x, y = [], []\n",
    "\n",
    "    for name in names:\n",
    "        name = \".\" + name + \".\"\n",
    "        tx, ty = [], []\n",
    "        for l1, l2 in zip(name, name[1:]):\n",
    "            tx.append(stoi[l1])\n",
    "            ty.append(stoi[l2])\n",
    "\n",
    "        if padding:\n",
    "            assert max_seq_len is not None\n",
    "            if len(tx) < max_seq_len:\n",
    "                tx.extend([stoi[\"<pad>\"]] * (max_seq_len - len(tx)))\n",
    "                ty.extend([stoi[\"<pad>\"]] * (max_seq_len - len(ty)))\n",
    "\n",
    "        x.append(tx)\n",
    "        y.append(ty)\n",
    "\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e2985b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([25626, 64]) torch.Size([25626, 64])\n",
      "torch.Size([3203, 64]) torch.Size([3203, 64])\n",
      "torch.Size([3204, 64]) torch.Size([3204, 64])\n"
     ]
    }
   ],
   "source": [
    "# first no padding, each instance is a batch\n",
    "train_x, train_y = create_data(train_names, padding=True, max_seq_len=64)\n",
    "val_x, val_y = create_data(val_names, padding=True, max_seq_len=64)\n",
    "test_x, test_y = create_data(test_names, padding=True, max_seq_len=64)\n",
    "\n",
    "train_x, train_y = torch.LongTensor(train_x), torch.LongTensor(train_y)\n",
    "val_x, val_y = torch.LongTensor(val_x), torch.LongTensor(val_y)\n",
    "test_x, test_y = torch.LongTensor(test_x), torch.LongTensor(test_y)\n",
    "\n",
    "print(train_x.shape, train_y.shape)\n",
    "print(val_x.shape, val_y.shape)\n",
    "print(test_x.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0dda841f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(train_x, train_y)\n",
    "val_dataset = TensorDataset(val_x, val_y)\n",
    "test_dataset = TensorDataset(test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2f988204",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([25626, 64])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.tensors[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "534f6f77",
   "metadata": {},
   "source": [
    "## Training code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "03ff71ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(dataset, model, criterion, device):\n",
    "    model.eval()\n",
    "    x = dataset.tensors[0].to(device) # (B, seq_len)\n",
    "    y = dataset.tensors[1].to(device) # (B, seq_len)\n",
    "\n",
    "    logits = model(x) # (B, C, V)\n",
    "    B, C, V = logits.shape\n",
    "    loss = criterion(logits.view(B * C, V), y.view(B * C))\n",
    "    return loss.item()\n",
    "\n",
    "def train_instance_wise(train_dataset, val_dataset, batch_size, n_eopchs, model, optimizer, criterion, device):\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=False)\n",
    "    val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True, drop_last=False)\n",
    "\n",
    "    train_loss_dict, val_loss_dict = {}, {}\n",
    "\n",
    "    train_loss = compute_loss(train_dataset, model, criterion, device)\n",
    "    val_loss = compute_loss(val_dataset, model, criterion, device)\n",
    "\n",
    "    print(f\"Start of training: Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "    for epoch in range(n_eopchs):\n",
    "        # train loop\n",
    "        model.train()\n",
    "        for x, y in train_dataloader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            logits = model(x)\n",
    "            B, C, V = logits.shape\n",
    "            loss = criterion(logits.view(B * C, V), y.view(B * C))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # Compute loss\n",
    "        train_loss = compute_loss(train_dataset, model, criterion, device)\n",
    "        val_loss = compute_loss(val_dataset, model, criterion, device)\n",
    "\n",
    "        train_loss_dict[epoch + 1] = train_loss\n",
    "        val_loss_dict[epoch + 1] = val_loss\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}: Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "    return train_loss_dict, val_loss_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bded692",
   "metadata": {},
   "source": [
    "## Step 2: Create a model (RNN Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, num_layers):\n",
    "        super().__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.rnn = nn.RNN(input_size=embedding_dim, hidden_size=hidden_dim, num_layers=num_layers, batch_first=True)\n",
    "        self.ln = nn.LayerNorm(hidden_dim)\n",
    "        self.ffn = nn.Linear(hidden_dim, vocab_size)\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        # init the embedings\n",
    "        init.xavier_normal_(self.embeddings.weight)\n",
    "\n",
    "        # Initialize RNN weights\n",
    "        for name, param in self.rnn.named_parameters():\n",
    "            if 'weight_ih' in name:  # input-to-hidden weights\n",
    "                init.xavier_normal_(param)\n",
    "            elif 'weight_hh' in name:  # hidden-to-hidden weights\n",
    "                init.xavier_normal_(param)\n",
    "            elif 'bias' in name:  # biases\n",
    "                init.zeros_(param)\n",
    "        \n",
    "        # Initialize output layer\n",
    "        init.xavier_normal_(self.ffn.weight)\n",
    "        init.zeros_(self.ffn.bias)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x shape (B, seq_len)\n",
    "        B, seq_len = x.shape\n",
    "\n",
    "        emb = self.embeddings(x) # (B, seq_len, emb_dim)\n",
    "\n",
    "        h0 = torch.zeros(self.num_layers, B, self.hidden_dim).to(device)\n",
    "        out, ht = self.rnn(emb, h0) # out shape: (B, seq_len, hidden_dim)\n",
    "        out = self.ln(out)\n",
    "        \n",
    "        logits = self.ffn(out) # logits shape: (B, seq_len, vocab_size)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86773747",
   "metadata": {},
   "source": [
    "### 1 layer RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d9e39c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(stoi)\n",
    "embedding_dim = 256\n",
    "hidden_dim = 256\n",
    "num_layers = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "194ddd9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNNModel(\n",
       "  (embeddings): Embedding(28, 256)\n",
       "  (rnn): RNN(256, 256, batch_first=True)\n",
       "  (ln): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "  (ffn): Linear(in_features=256, out_features=28, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RNNModel(vocab_size=len(stoi), embedding_dim=embedding_dim, hidden_dim=hidden_dim, num_layers=num_layers)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "28006d01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters in model1: 146460\n"
     ]
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Total parameters in model1: {total_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a4e7767d",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "n_epochs = 20\n",
    "lr = 0.002\n",
    "optimizer = optim.AdamW(model.parameters(), lr=lr)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=stoi[\"<pad>\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bc7f0d2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start of training: Train Loss: 3.3484, Val Loss: 3.3499\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss: 2.2175, Val Loss: 2.2261\n",
      "Epoch 2: Train Loss: 2.1510, Val Loss: 2.1674\n",
      "Epoch 3: Train Loss: 2.1017, Val Loss: 2.1276\n",
      "Epoch 4: Train Loss: 2.0595, Val Loss: 2.0941\n",
      "Epoch 5: Train Loss: 2.0227, Val Loss: 2.0661\n",
      "Epoch 6: Train Loss: 2.0019, Val Loss: 2.0585\n",
      "Epoch 7: Train Loss: 1.9682, Val Loss: 2.0340\n",
      "Epoch 8: Train Loss: 1.9521, Val Loss: 2.0316\n",
      "Epoch 9: Train Loss: 1.9288, Val Loss: 2.0197\n",
      "Epoch 10: Train Loss: 1.9147, Val Loss: 2.0110\n",
      "Epoch 11: Train Loss: 1.8980, Val Loss: 2.0077\n",
      "Epoch 12: Train Loss: 1.8903, Val Loss: 2.0047\n",
      "Epoch 13: Train Loss: 1.8770, Val Loss: 2.0027\n",
      "Epoch 14: Train Loss: 1.8636, Val Loss: 1.9988\n",
      "Epoch 15: Train Loss: 1.8515, Val Loss: 1.9958\n",
      "Epoch 16: Train Loss: 1.8414, Val Loss: 1.9989\n",
      "Epoch 17: Train Loss: 1.8316, Val Loss: 1.9954\n",
      "Epoch 18: Train Loss: 1.8264, Val Loss: 1.9997\n",
      "Epoch 19: Train Loss: 1.8144, Val Loss: 1.9952\n",
      "Epoch 20: Train Loss: 1.8070, Val Loss: 1.9975\n"
     ]
    }
   ],
   "source": [
    "train_loss_dict, val_loss_dict = train_instance_wise(train_dataset, val_dataset, batch_size, n_epochs, model, optimizer, criterion, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82dc8212",
   "metadata": {},
   "source": [
    "lr = 0.002\n",
    "Train Loss: 1.8070, Val Loss: 1.9975"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8134ed50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9966771602630615\n"
     ]
    }
   ],
   "source": [
    "test_loss = compute_loss(test_dataset, model, criterion, device)\n",
    "print(test_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ce9049",
   "metadata": {},
   "source": [
    "### 2 layer RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "80bd95f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(stoi)\n",
    "embedding_dim = 256\n",
    "hidden_dim = 256\n",
    "num_layers = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "97bfa64d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNNModel(\n",
       "  (embeddings): Embedding(28, 256)\n",
       "  (rnn): RNN(256, 256, num_layers=2, batch_first=True)\n",
       "  (ln): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "  (ffn): Linear(in_features=256, out_features=28, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RNNModel(vocab_size=len(stoi), embedding_dim=embedding_dim, hidden_dim=hidden_dim, num_layers=num_layers)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "df7ddab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters in model1: 278044\n"
     ]
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Total parameters in model1: {total_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1ca60d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "n_epochs = 20\n",
    "lr = 0.001\n",
    "optimizer = optim.AdamW(model.parameters(), lr=lr)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=stoi[\"<pad>\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5ea8caab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start of training: Train Loss: 4.3736, Val Loss: 4.3664\n",
      "Epoch 1: Train Loss: 2.2449, Val Loss: 2.2556\n",
      "Epoch 2: Train Loss: 2.1895, Val Loss: 2.2039\n",
      "Epoch 3: Train Loss: 2.1476, Val Loss: 2.1673\n",
      "Epoch 4: Train Loss: 2.1152, Val Loss: 2.1407\n",
      "Epoch 5: Train Loss: 2.0821, Val Loss: 2.1150\n",
      "Epoch 6: Train Loss: 2.0551, Val Loss: 2.0930\n",
      "Epoch 7: Train Loss: 2.0221, Val Loss: 2.0697\n",
      "Epoch 8: Train Loss: 1.9951, Val Loss: 2.0550\n",
      "Epoch 9: Train Loss: 1.9764, Val Loss: 2.0438\n",
      "Epoch 10: Train Loss: 1.9590, Val Loss: 2.0370\n",
      "Epoch 11: Train Loss: 1.9346, Val Loss: 2.0237\n",
      "Epoch 12: Train Loss: 1.9165, Val Loss: 2.0199\n",
      "Epoch 13: Train Loss: 1.9007, Val Loss: 2.0147\n",
      "Epoch 14: Train Loss: 1.8862, Val Loss: 2.0100\n",
      "Epoch 15: Train Loss: 1.8690, Val Loss: 2.0038\n",
      "Epoch 16: Train Loss: 1.8549, Val Loss: 2.0041\n",
      "Epoch 17: Train Loss: 1.8397, Val Loss: 1.9972\n",
      "Epoch 18: Train Loss: 1.8322, Val Loss: 2.0046\n",
      "Epoch 19: Train Loss: 1.8104, Val Loss: 1.9929\n",
      "Epoch 20: Train Loss: 1.7998, Val Loss: 1.9952\n"
     ]
    }
   ],
   "source": [
    "train_loss_dict, val_loss_dict = train_instance_wise(train_dataset, val_dataset, batch_size, n_epochs, model, optimizer, criterion, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba19d7d",
   "metadata": {},
   "source": [
    "lr = 0.002\n",
    "Train Loss: 1.8070, Val Loss: 1.9975"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b704b77e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9841831922531128\n"
     ]
    }
   ],
   "source": [
    "test_loss = compute_loss(test_dataset, model, criterion, device)\n",
    "print(test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6d46cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def clear_gpu_memory_pytorch():\n",
    "    \"\"\"Clears PyTorch's CUDA cache.\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "        print(\"PyTorch CUDA cache cleared.\")\n",
    "    else:\n",
    "        print(\"CUDA is not available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e18808d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Jun 28 20:03:12 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 560.35.03              Driver Version: 560.35.03      CUDA Version: 12.6     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 4090        On  |   00000000:46:00.0 Off |                  Off |\n",
      "|  0%   50C    P8              4W /  450W |     482MiB /  24564MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c180ef01",
   "metadata": {},
   "source": [
    "## Test pretrain code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29c023c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "vocab = set()\n",
    "vocab.update(string.ascii_lowercase)\n",
    "vocab.add(\".\")\n",
    "vocab.add(\"<pad>\")\n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "60eaf901",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_file(input_path):\n",
    "    with open(input_path, 'r', encoding='utf-8') as infile:\n",
    "        content = infile.read()\n",
    "    \n",
    "    # Convert to lowercase\n",
    "    content = content.lower()\n",
    "    \n",
    "    # Retain only lowercase letters, dots, spaces, and newlines\n",
    "    cleaned = re.sub(r'[^a-z.\\n ]', '', content)\n",
    "    return cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a0c258a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the happy prince.\\nhigh above the city on a tall column stood the statue of the happy prince.  he was gilded all over with thin leaves of fine gold for eyes he had two bright sapphires and a large red '"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = \"/root/makemore/personal-extension/character_level_lm/cleaned_merged_fairy_tales_without_eos.txt\"\n",
    "cleaned = clean_file(file_path)\n",
    "cleaned[:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ccc38a3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16364504, 64) (16364504, 64)\n",
      "(2045563, 64) (2045563, 64)\n",
      "(2045563, 64) (2045563, 64)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "torch.Size([16364504, 64]) torch.Size([16364504, 64])\n",
      "torch.Size([2045563, 64]) torch.Size([2045563, 64])\n",
      "torch.Size([2045563, 64]) torch.Size([2045563, 64])\n"
     ]
    }
   ],
   "source": [
    "data = np.load(\"/root/makemore/personal-extension/character_level_lm/pretrain_data/pretrain_data_seq_len_64.npz\")\n",
    "x_train, y_train, x_val, y_val, x_test, y_test = data[\"x_train\"], data[\"y_train\"],\\\n",
    "        data[\"x_val\"], data[\"y_val\"], data[\"x_test\"], data[\"y_test\"]\n",
    "\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(x_val.shape, y_val.shape)\n",
    "print(x_test.shape, y_test.shape)\n",
    "\n",
    "print(\"-\" * 100)\n",
    "\n",
    "train_x, train_y = torch.LongTensor(x_train), torch.LongTensor(y_train)\n",
    "val_x, val_y = torch.LongTensor(x_val), torch.LongTensor(y_val)\n",
    "test_x, test_y = torch.LongTensor(x_test), torch.LongTensor(y_test)\n",
    "\n",
    "print(train_x.shape, train_y.shape)\n",
    "print(val_x.shape, val_y.shape)\n",
    "print(test_x.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ba0cc488",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([59, 74, 74, 83,  1, 45, 76, 67, 72, 61, 63, 13,  0, 37, 38, 36, 37,  1,\n",
       "        59, 60, 73, 80, 63,  1, 78, 66, 63,  1, 61, 67, 78, 83, 11,  1, 73, 72,\n",
       "         1, 59,  1, 78, 59, 70, 70,  1, 61, 73, 70, 79, 71, 72, 11,  1, 77, 78,\n",
       "        73, 73, 62,  1, 78, 66, 63,  1, 77, 78])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "63e88fd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([74, 74, 83,  1, 45, 76, 67, 72, 61, 63, 13,  0, 37, 38, 36, 37,  1, 59,\n",
       "        60, 73, 80, 63,  1, 78, 66, 63,  1, 61, 67, 78, 83, 11,  1, 73, 72,  1,\n",
       "        59,  1, 78, 59, 70, 70,  1, 61, 73, 70, 79, 71, 72, 11,  1, 77, 78, 73,\n",
       "        73, 62,  1, 78, 66, 63,  1, 77, 78, 59])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb99df3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
